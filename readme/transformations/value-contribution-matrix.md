# Value Contribution Matrix

### Key Aspects

1. Eisenhower Matrix [#the-eisenhower-matrix](value-contribution-matrix.md#the-eisenhower-matrix "mention")
2. Pareto and Gaussian distributions [#pareto-and-gaussian-normal-distributions](value-contribution-matrix.md#pareto-and-gaussian-normal-distributions "mention")
3. System 1 vs System 2 Thinking [#what-is-system-1-and-system-2-thinking](value-contribution-matrix.md#what-is-system-1-and-system-2-thinking "mention")
4. Complicated vs Complex [#complicated-vs-complex](value-contribution-matrix.md#complicated-vs-complex "mention")
5. Novelty vs Repetition [#recipes-vs-chefs](value-contribution-matrix.md#recipes-vs-chefs "mention")
6. Resilience vs Robustness [#resilience-vs-robustness](value-contribution-matrix.md#resilience-vs-robustness "mention")
7. [#you-design-how-you-do-your-work](value-contribution-matrix.md#you-design-how-you-do-your-work "mention")
8. Cost of recovery (Early Detection and not Prevention)
9. Cost of amplification (Detection and minimise blast radius)
10. A degree of foresight (can anticipate in certain environment, and not in uncertainty)
11. Professional negligence/omission/malpractice&#x20;
12. Criminal breach of trust

#### The Eisenhower Matrix

{% hint style="info" %}
This has limited usage in Complex Adaptive System context; because important or not is decided using Gaussian distribution, more on [#pareto-and-gaussian-normal-distributions](value-contribution-matrix.md#pareto-and-gaussian-normal-distributions "mention")
{% endhint %}

> The Eisenhower Matrix, also referred to as Urgent-Important Matrix, helps you decide on and prioritize tasks by urgency and importance, sorting out less urgent and important tasks which you should either delegate or not do at all.
>
> [https://www.eisenhower.me/eisenhower-matrix/](https://www.eisenhower.me/eisenhower-matrix/)

#### Pareto and Gaussian (normal) distributions

<figure><img src="../../.gitbook/assets/image (1).png" alt=""><figcaption><p><a href="https://hbr.org/data-visuals/2021/12/a-pareto-distribution-vs-a-gaussian-curve">https://hbr.org/data-visuals/2021/12/a-pareto-distribution-vs-a-gaussian-curve</a></p></figcaption></figure>

> Dave Snowden uses the distinction between Pareto and Gaussian (normal) distributions to illustrate different dynamics in complex systems. He highlights that while many business and management approaches assume a Gaussian distribution (with predictable outcomes and a focus on averages), real-world situations, particularly in complex or chaotic domains, often follow a Pareto distribution, characterized by a few high-impact events and many minor ones.
>
> In complex systems, the Pareto distribution is more typical. This means that relying on averages and ignoring outliers is a flawed strategy. Instead, one needs to focus on understanding the drivers of the few high-impact events and managing the system accordingly.
>
> In a Pareto world, strategies cannot be based solely on probability assessments. Safe-to-fail experiments and understanding the dynamics of the system are more appropriate.
>
> — Google AO Overview for '"Pareto distribution and Gaussian distribution snowden"

#### What is System 1 and System 2 Thinking?

<figure><img src="../../.gitbook/assets/image.png" alt=""><figcaption></figcaption></figure>

> System 1 and System 2 thinking describes two distinct modes of cognitive processing introduced by Daniel Kahneman in his book Thinking, Fast and Slow. System 1 is fast, automatic, and intuitive, operating with little to no effort. This mode of thinking allows us to make quick decisions and judgments based on patterns and experiences. In contrast, System 2 is slow, deliberate, and conscious, requiring intentional effort. This type of thinking is used for complex problem-solving and analytical tasks where more thought and consideration are necessary.
>
>
>
> > _The automatic operations of System 1 generate surprisingly complex patterns of ideas, but only the slower System 2 can construct thoughts in an orderly series of steps._\
> > &#xNAN;_**– Daniel Kahneman** in Thinking, Fast and Slow_
>
> [https://thedecisionlab.com/reference-guide/philosophy/system-1-and-system-2-thinking](https://thedecisionlab.com/reference-guide/philosophy/system-1-and-system-2-thinking)

#### Complicated vs Complex

> In the context of strategy, the key distinction within Cynefin is that between systems that are complicated and those that are complex. The former can be engineered and diagnosis can be separated from intervention, the latter cannot and all diagnostic attempts are a priori interventions and vice versa.

#### Recipes vs Chefs&#x20;

> A simple metaphor will allow us to understand the danger of the case based, structured approaches that have dominated the last few decades; namely that of the recipe book user and the chef. If you employ a recipe book user to cook a meal for you, then your kitchen will have to be engineered to match a standard design. All the ingredients will be lined up in appropriate sized bowls and, as long as nothing unexpected happens you will get a reasonable meal. The Chef on the other hand enters your kitchen and creates a wonderful meal from whatever happens to be lying around. This is not to say that recipe books do not have utility, or that the chef will not use them from time to time. The point is that the chef is resilient and adaptive in changing contexts; the recipe book is not. The reason for this is that, to reference Aristotle, the chef has both _sophia_ and _pronesis_, the ability to reflect and the knowledge built through a long apprenticeship and an understanding of the basic principles of taste and nutrition; wisdom both reflective and practical, institutionalized in social practice and expectation.
>
>
>
> Put bluntly, the emphasis on engineering best practice and case based approaches to management science over the last few decades has produced an over dependence on recipes, and a paucity of chefs. Rectification of this is a matter of necessity in a resource-starved future confronted by increasing levels of uncertainty and less and less time to react or intervene before events get out of hand. The purpose of this chapter however is not to declare the engineering approach apostate and establish cognitive complexity<sup>1</sup> as a new religious orthodoxy. Rather it is to legitimize such approaches, within the boundaries of Ordered Systems, where cause and effect relationships exist, can be discovered and which repeat. On the other side of the boundary however we have a whole new class of un-ordered<sup>2</sup> systems that require the adaptability of the chef, rather than the predictability of the recipe book.

### Resilience vs Robustness

> Resilience for the purposes of this chapter is defined as the capacity to recover quickly from failure (including the consequences of external change outside of the decision maker’s control), and robustness as the capacity to resist failure. Taking a strategic approach based on resilience also implies the early detection of signs of failure to minimize the energy cost of recovery. The signs of potential success, or success through failure, also require early detection to reduce energy costs of amplification. Robustness under this definition requires a degree of foresight; we have to anticipate the likely range of events with which we will have to deal and that, as we will see, is highly problematic under conditions of uncertainty.

#### You Design How you Do Your Work

The larger point I wanted to make is that you don’t just do your work, you design how you do your work — Kent Beck

{% embed url="https://substack.com/@anan12/note/c-102456723?utm_source=notes-share-action&r=299fmk" %}

{% hint style="info" %}
While simply being complacent might not be a crime, the consequences of that complacency, such as enabling fraud or negligence leading to injury, could result in criminal charges.
{% endhint %}
